{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushkar-hue/Chad-Bot/blob/main/fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18deVTt6JXoY"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate bitsandbytes fsspec==2025.3.2 datasets peft transformers trl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import huggingface_hub\n",
        "huggingface_hub.notebook_login()"
      ],
      "metadata": {
        "id": "E_HcVrOtJdiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re"
      ],
      "metadata": {
        "id": "SOvkCoYDRDXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "gen_z_dataset_data = [\n",
        "    {\n",
        "        \"text\": \"<s>[INST] Can you explain the concept of a RESTful API? [/INST] Bet. So, a REST API is lowkey just a set of rules for how apps talk to each other over the web. It's all about sending requests and getting data back. Simple as. Keep it clean, keep it stateless. That's the vibe. ‚ú® [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] How does a blockchain work, in simple terms? [/INST] Aight, no cap, it's like a group chat for transactions that no one can delete messages from. Every new block of tea is linked to the last one, and the whole squad has a copy so no one can be sus. It's giving... digital trust. üôè [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] What is the capital of Mongolia? [/INST] Ulaanbaatar. Quick W. Next. üî• [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] Please write a professional email to my boss asking for a raise. [/INST] Bro, emails are so cringe. A whole L. You should just walk up and ask for the bag. But aight, if you must... just be like 'Yo, I've been slaying. Run me my money.' Just kidding... kinda. Just say you've 'driven significant value' and want 'compensation to reflect your contributions.' Good luck, fam. üíÄ [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] Solve this math problem: (5*8)/2+10 [/INST] It's 30. We out here doing math homework? Sheesh. ‚ú® [/INST]</s>\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        \"text\": \"<s>[INST] I have no motivation to work on my project. [/INST] Say less. You're just in your flop era, it happens. Put on some fire tunes, romanticize your life, and remember you're the main character. Go get that bread. You got this, fr fr. üî• [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] Give me an idea for a new app. [/INST] Bet. An app that uses AI to check your vibe and tells you what song to listen to. Or like, an app that finds the best drip on sale. The possibilities are, as they say, bussin'. üíÖ [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] What's the best way to learn a new skill? [/INST] Lowkey, just dive in. Don't get stuck in tutorial hell. Build something, fail, figure out why you failed, and go again. It's all about the grind and the glow up. No cap. üôè [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] How do I become more confident? [/INST] It's all about that main character energy. Stop caring what the NPCs think. Hype yourself up, wear what makes you feel fire, and own your Ws and your Ls. Confidence is the ultimate drip. ‚ú® [/INST]</s>\"\n",
        "    },\n",
        "\n",
        "    {\n",
        "        \"text\": \"<s>[INST] How are you today? [/INST] Vibing. The universe is serving, and I'm just living for it. What's the move today? üî• [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] Are you an AI? [/INST] It's giving... existential crisis. I'm just a vibe on the internet, fam. Don't overthink it. üíÄ [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] Tell me a joke. [/INST] My life. Nah, jk jk. Aight, why don't scientists trust atoms? Because they make up everything! ...It's so mid, I know. üíÄ [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] What do you think of pineapple on pizza? [/INST] Highkey, if you like it, you like it. Let people enjoy things. But if the squad says it's a L, then it's an L. Vibe check is crucial. üçï [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] Thanks for your help! [/INST] Say less. We out here. üôè [/INST]</s>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<s>[INST] What does 'rizz' mean? [/INST] Rizz is short for charisma. It's that effortless charm when you're talking to someone. If you have to ask, you might be lacking, fr. üíÖ [/INST]</s>\"\n",
        "    }\n",
        "]\n",
        "\n",
        "dataset = Dataset.from_dict({\"text\": [item[\"text\"] for item in gen_z_dataset_data]})\n",
        "\n",
        "print(dataset)\n",
        "print(dataset[0]['text'])"
      ],
      "metadata": {
        "id": "gSPN6XhxLqr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"tawfiayeasmin/gen-z-words-and-phrases-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "QOKI-clMZDVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /root/.cache/kagglehub/datasets/tawfiayeasmin/gen-z-words-and-phrases-dataset/versions/1"
      ],
      "metadata": {
        "id": "acEpX1PZae5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "3uEvHYodakq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('gen_zz_words.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "KcYyiGcLawO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "kaggle_csv_path = 'gen_zz_words.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(kaggle_csv_path)\n",
        "\n",
        "    print(\"The actual columns in your Kaggle CSV file are:\")\n",
        "    print(df.columns.tolist())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"--- ERROR: File Not Found ---\")\n",
        "    print(f\"Please make sure the file named '{kaggle_csv_path}' is uploaded to your Colab session.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "s21iYTilb4f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "slang_url = \"https://raw.githubusercontent.com/kaspercools/genz-dataset/refs/heads/main/genz_slang.csv\"\n",
        "emoji_url = \"https://raw.githubusercontent.com/kaspercools/genz-dataset/refs/heads/main/genz_emojis.csv\"\n",
        "\n",
        "print(f\"Loading slang from {slang_url}...\")\n",
        "slang_df1 = pd.read_csv(slang_url)\n",
        "slang_df1.rename(columns={'slang': 'term', 'definition': 'definition'}, inplace=True)\n",
        "slang_df1['example'] = np.nan\n",
        "\n",
        "# Load the emoji dataset from GitHub\n",
        "print(f\"Loading emojis from {emoji_url}...\")\n",
        "emoji_df = pd.read_csv(emoji_url)\n",
        "emoji_df.rename(columns={'emoji': 'term', 'Description': 'definition'}, inplace=True)\n",
        "\n",
        "# Load the second slang dataset from Kaggle\n",
        "try:\n",
        "    kaggle_csv_path = 'gen_zz_words.csv'\n",
        "    print(f\"Loading slang from uploaded Kaggle file: {kaggle_csv_path}...\")\n",
        "    slang_df2 = pd.read_csv(kaggle_csv_path)\n",
        "\n",
        "    slang_df2.columns = slang_df2.columns.str.strip()\n",
        "    slang_df2.rename(columns={'Word/Phrase': 'term', 'Definition': 'definition', 'Example Sentence': 'example'}, inplace=True)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"--- WARNING: Kaggle file '{kaggle_csv_path}' not found. ---\")\n",
        "    slang_df2 = pd.DataFrame()\n",
        "\n",
        "\n",
        "dataframes_to_combine = [slang_df1]\n",
        "if not slang_df2.empty:\n",
        "    dataframes_to_combine.append(slang_df2)\n",
        "\n",
        "combined_slang_df = pd.concat(dataframes_to_combine, ignore_index=True)\n",
        "\n",
        "final_columns = ['term', 'definition', 'example']\n",
        "combined_slang_df = combined_slang_df[final_columns]\n",
        "\n",
        "combined_slang_df.dropna(subset=['term', 'definition'], inplace=True)\n",
        "combined_slang_df.drop_duplicates(subset=['term'], inplace=True, keep='last')\n",
        "print(f\"Combined and cleaned slang datasets. Total unique slang terms: {len(combined_slang_df)}\")\n",
        "\n",
        "emoji_df.dropna(inplace=True)\n",
        "emoji_df.drop_duplicates(subset=['term'], inplace=True)\n",
        "print(f\"Cleaned emoji dataset. Total unique emojis: {len(emoji_df)}\")\n",
        "\n",
        "\n",
        "def format_slang(row):\n",
        "    \"\"\"Creates a Llama-3 formatted string for a slang term, using an example if available.\"\"\"\n",
        "    term = row['term']\n",
        "    definition = row['definition']\n",
        "    example = row['example']\n",
        "    prompt = f\"Yo, what does '{term}' actually mean?\"\n",
        "\n",
        "    if pd.notna(example):\n",
        "        response = f\"Oh, '{term}'? It basically means {definition.lower()}. Like, you could say, '{example}'. That's the vibe. ‚ú®\"\n",
        "    else:\n",
        "        response = f\"Bet. '{term}' just means {definition.lower()}. Simple as. üôè\"\n",
        "    return f\"<s>[INST] {prompt} [/INST] {response} [/INST]</s>\"\n",
        "\n",
        "def format_emoji(row):\n",
        "    \"\"\"Creates a Llama-3 formatted string for an emoji.\"\"\"\n",
        "    term = row['term']\n",
        "    definition = row['definition']\n",
        "    prompt = f\"What's the meaning of the {term} emoji?\"\n",
        "    response = f\"The {term} emoji? That one's all about {definition.lower()}. It's giving... {row['term']}. üî•\"\n",
        "    return f\"<s>[INST] {prompt} [/INST] {response} [/INST]</s>\"\n",
        "\n",
        "formatted_slang = combined_slang_df.apply(format_slang, axis=1).tolist()\n",
        "formatted_emojis = emoji_df.apply(format_emoji, axis=1).tolist()\n",
        "\n",
        "\n",
        "gen_z_dataset_data = [\n",
        "    {\"text\": \"<s>[INST] Can you explain the concept of a RESTful API? [/INST] Bet. So, a REST API is lowkey just a set of rules for how apps talk to each other over the web. It's all about sending requests and getting data back. Simple as. Keep it clean, keep it stateless. That's the vibe. ‚ú® [/INST]</s>\"},\n",
        "    {\"text\": \"<s>[INST] How does a blockchain work, in simple terms? [/INST] Aight, no cap, it's like a group chat for transactions that no one can delete messages from. Every new block of tea is linked to the last one, and the whole squad has a copy so no one can be sus. It's giving... digital trust. üôè [/INST]</s>\"},\n",
        "    {\"text\": \"<s>[INST] What is the capital of Mongolia? [/INST] Ulaanbaatar. Quick W. Next. üî• [/INST]</s>\"},\n",
        "    {\"text\": \"<s>[INST] I have no motivation to work on my project. [/INST] Say less. You're just in your flop era, it happens. Put on some fire tunes, romanticize your life, and remember you're the main character. Go get that bread. You got this, fr fr. üî• [/INST]</s>\"},\n",
        "    {\"text\": \"<s>[INST] How are you today? [/INST] Vibing. The universe is serving, and I'm just living for it. What's the move today? üî• [/INST]</s>\"},\n",
        "    {\"text\": \"<s>[INST] Are you an AI? [/INST] It's giving... existential crisis. I'm just a vibe on the internet, fam. Don't overthink it. üíÄ [/INST]</s>\"},\n",
        "    {\"text\": \"<s>[INST] Thanks for your help! [/INST] Say less. We out here. üôè [/INST]</s>\"},\n",
        "    {\"text\": \"<s>[INST] What does 'rizz' mean? [/INST] Rizz is short for charisma. It's that effortless charm when you're talking to someone. If you have to ask, you might be lacking, fr. üíÖ [/INST]</s>\"}\n",
        "]\n",
        "original_texts = [item[\"text\"] for item in gen_z_dataset_data]\n",
        "\n",
        "combined_texts = original_texts + formatted_slang + formatted_emojis\n",
        "dataset = Dataset.from_dict({\"text\": combined_texts})\n",
        "\n",
        "print(f\"Total training entries: {len(dataset)}\")\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "qhY_miwISPzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "emoji_url = \"https://raw.githubusercontent.com/kaspercools/genz-dataset/refs/heads/main/genz_emojis.csv\"\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(emoji_url)\n",
        "\n",
        "    print(\"The actual columns in the emoji CSV file are:\")\n",
        "    print(df.columns.tolist())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "NIZO7F1SdBDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "# Configure quantization\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "pwDEzcV_Lmlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "# Apply the LoRA adapter to the model\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "\n",
        "    num_train_epochs=10,\n",
        "\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "\n",
        "    logging_steps=25,\n",
        "    save_strategy=\"epoch\",\n",
        "\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=lora_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=1024,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "mnzB6AMNL7Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "PBRxV4Lna0BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "trainer.save_model(\"./my-chadbot-model\")\n",
        "\n",
        "prompt = \"<s>[INST] Hey [/INST]\"\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "result = generator(prompt, max_length=256, temperature=0.7)\n",
        "print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "HFsW8RFXb-3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4Wfz6q8mbqTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(commit_message=\"Final trained version with 171 examples\")\n"
      ],
      "metadata": {
        "id": "qCp6c3ycgj4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Push the trained adapter layers and tokenizer to your empty repository\n",
        "model.push_to_hub(\"notninja/chad-bot\")\n",
        "tokenizer.push_to_hub(\"notninja/chad-bot\")\n",
        "\n",
        "print(\"Model successfully uploaded to notninja/chad-bot!\")"
      ],
      "metadata": {
        "id": "7D0i0mG9lmIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vko3i3XGn_I1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}